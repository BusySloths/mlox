version: '3.8'

volumes:
    prometheus_data: {}
    grafana_data: {}

networks:
  monitor-net:

services:

  prometheus:
    image: prom/prometheus:v2.53.1
    volumes:
      - ./prometheus/:/etc/prometheus/
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    ports:
      - 9090:9090
    depends_on:
      - cadvisor
#      - pushgateway
    networks:
      - monitor-net
    deploy:
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: on-failure

  node-exporter:
    image: quay.io/prometheus/node-exporter:latest
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command: 
      - '--path.procfs=/host/proc' 
      - '--path.sysfs=/host/sys'
      - --collector.filesystem.ignored-mount-points
      - "^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)"
    ports:
      - 9100:9100
    networks:
      - monitor-net
    deploy:
      mode: global
      restart_policy:
          condition: on-failure

  alertmanager:
    image: prom/alertmanager
    ports:
      - 9093:9093
    volumes:
      - "./alert-config.yaml:/etc/alertmanager/config.yaml"
    networks:
      - monitor-net
    command:
      - '--config.file=/etc/alertmanager/config.yaml'
      - '--storage.path=/alertmanager'
    deploy:
      placement:
        constraints:
           - node.role==manager
      restart_policy:
        condition: on-failure    

  cadvisor:
    image: gcr.io/cadvisor/cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    ports:
      - 8080:8080
    networks:
      - monitor-net
    deploy:
      mode: global
      restart_policy:
          condition: on-failure

  # Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.105.0
    restart: always
    command: ["--config=/etc/otel-collector-config.yaml"]
    networks:
      - monitor-net
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "1888:1888"   # pprof extension
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP http receiver
      - "55679:55679" # zpages extension

  # Jaeger
  jaeger-all-in-one:
    image: jaegertracing/all-in-one:latest
    restart: always
    environment:
      - METRICS_STORAGE_TYPE=prometheus
      - PROMETHEUS_SERVER_URL=http://prometheus:9090
      - PROMETHEUS_QUERY_SUPPORT_SPANMETRICS_CONNECTOR=true
      - PROMETHEUS_QUERY_NAMESPACE=myspanmetrics
      - PROMETHEUS_QUERY_NORMALIZE_CALLS=true
      - PROMETHEUS_QUERY_NORMALIZE_DURATION=true    
      - QUERY_ENABLE_TRACING=true
      # - COLLECTOR_OTLP_ENABLED=true
    networks:
      - monitor-net
    ports:
      - "16686:16686" 
      - "16687:16687" 
      - "14268"
      - "14269"
      - "14250"

  # Jaeger-HotRod
  jaeger-HotRod:
    image: jaegertracing/example-hotrod:latest
    depends_on: 
      - jaeger-all-in-one
    environment:
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318
    networks:
      - monitor-net
    ports:
      - "7080-7083:8080-8083"

  grafana:
    image: grafana/grafana
    depends_on:
      - prometheus
    ports:
      - 3000:3000
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/:/etc/grafana/provisioning/
    env_file:
      - ./grafana/config.monitoring
    networks:
      - monitor-net
    user: "472"
    deploy:
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: on-failure